{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking all scenes and all dialogue objects (\\<OBJ>) are in the img_embedding dict from UNITER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38127\n",
      "38127\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data_object_special/simmc2_scenes_train.txt\", 'r') as f:\n",
    "    train_scenes = json.load(f)\n",
    "\n",
    "with open(\"./data_object_special/simmc2_dials_dstc10_train_predict.txt\", 'r') as f:\n",
    "    train_data = f.readlines()\n",
    "\n",
    "print(len(train_scenes))\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8609\n",
      "8609\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data_object_special/simmc2_scenes_devtest.txt\", 'r') as f:\n",
    "    devtest_scenes = json.load(f)\n",
    "\n",
    "with open(\"./data_object_special/simmc2_dials_dstc10_devtest_predict.txt\", 'r') as f:\n",
    "    devtest_data = f.readlines()\n",
    "\n",
    "print(len(devtest_scenes))\n",
    "print(len(devtest_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRUPTED_IMGS = ['cloth_store_1416238_woman_4_8', 'm_cloth_store_1416238_woman_20_6', 'cloth_store_1416238_woman_20_6', 'cloth_store_1416238_woman_19_0']\n",
    "\n",
    "img_feat = torch.load(\"./data_object_special/img_features.pt\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,line in enumerate(train_data):\n",
    "    if train_scenes[idx] not in CORRUPTED_IMGS:\n",
    "        l1 = len([m.start() for m in re.finditer('<OBJ>', line)])\n",
    "        l2 = len(img_feat[train_scenes[idx]+'_scene'].keys())-1\n",
    "        if l1!=l2:\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,line in enumerate(devtest_data):\n",
    "    if devtest_scenes[idx] not in CORRUPTED_IMGS:\n",
    "        l1 = len([m.start() for m in re.finditer('<OBJ>', line)])\n",
    "        l2 = len(img_feat[devtest_scenes[idx]+'_scene'].keys())-1\n",
    "        if l1!=l2:\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRUPTED_IMGS = ['cloth_store_1416238_woman_4_8', 'm_cloth_store_1416238_woman_20_6', 'cloth_store_1416238_woman_20_6', 'cloth_store_1416238_woman_19_0']\n",
    "\n",
    "img_feat = torch.load(\"./data_object_special/img_features.pt\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_object_special/simmc2_scenes_train.txt', 'r') as f:\n",
    "    train_scenes = json.load(f)\n",
    "\n",
    "with open('./data_object_special/simmc2_scenes_dev.txt', 'r') as f:\n",
    "    dev_scenes = json.load(f)\n",
    "\n",
    "with open('./data_object_special/simmc2_scenes_devtest.txt', 'r') as f:\n",
    "    devtest_scenes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Dev...\n",
      "Devtest...\n"
     ]
    }
   ],
   "source": [
    "def check_scenes(data):\n",
    "    for scene in data:\n",
    "        if scene not in CORRUPTED_IMGS:\n",
    "            if scene+'_scene' not in img_feat:\n",
    "                print(scene+'_scene')\n",
    "                break\n",
    "\n",
    "print(\"Train...\")\n",
    "check_scenes(train_scenes)\n",
    "print(\"Dev...\")\n",
    "check_scenes(dev_scenes)\n",
    "print(\"Devtest...\")\n",
    "check_scenes(devtest_scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/simmc2_dials_dstc10_train.json\", 'r') as f:\n",
    "    train_data =json.load(f)\n",
    "\n",
    "with open(\"./data/simmc2_dials_dstc10_dev.json\", 'r') as f:\n",
    "    dev_data =json.load(f)\n",
    "\n",
    "with open(\"./data/simmc2_dials_dstc10_devtest.json\", 'r') as f:\n",
    "    devtest_data =json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7307 4667 2640\n",
      "563 563 0\n",
      "1687 1172 515\n",
      "9557\n",
      "6402\n",
      "3155\n"
     ]
    }
   ],
   "source": [
    "def calc_stats(data):\n",
    "    n_total = 0\n",
    "    n_fash = 0\n",
    "    n_furn = 0\n",
    "\n",
    "    for dial in data['dialogue_data']:\n",
    "        n_total += 1\n",
    "        if dial['domain'] == 'fashion':\n",
    "            n_fash += 1\n",
    "        else:\n",
    "            n_furn += 1\n",
    "        \n",
    "    return n_total, n_fash, n_furn\n",
    "\n",
    "n_total_train, n_fash_train, n_furn_train = calc_stats(train_data)\n",
    "n_total_dev, n_fash_dev, n_furn_dev = calc_stats(dev_data)\n",
    "n_total_devtest, n_fash_devtest, n_furn_devtest = calc_stats(devtest_data)\n",
    "\n",
    "print(n_total_train, n_fash_train, n_furn_train)\n",
    "print(n_total_dev, n_fash_dev, n_furn_dev)\n",
    "print(n_total_devtest, n_fash_devtest, n_furn_devtest)\n",
    "print(n_total_train + n_total_dev + n_total_devtest)\n",
    "print(n_fash_train + n_fash_dev + n_fash_devtest)\n",
    "print(n_furn_train + n_furn_dev + n_furn_devtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing script to get BART examples splitting from UNITER splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38127\n",
      "27567 10560 38127\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data_object_special/simmc2_dials_dstc10_train_predict.txt\", 'r') as f:\n",
    "    train_pred_data = f.readlines()\n",
    "\n",
    "print(len(train_pred_data))\n",
    "\n",
    "fash = 0\n",
    "furn = 0\n",
    "for line in train_pred_data:\n",
    "    k = line.find(\"<@\")\n",
    "    if line[k+2] == '1':\n",
    "        fash +=1\n",
    "    elif line[k+2] == '2':\n",
    "        furn +=1\n",
    "    else:\n",
    "        print(\"Error:\", line)\n",
    "print(fash, furn, fash+furn)\n",
    "\n",
    "# Out of domain is well built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORE_BASE_PATH = \"./data_object_special/new_datasets/\"\n",
    "REF_SETS_BASE_PATH = STORE_BASE_PATH+\"reference_sets\"\n",
    "\n",
    "TRAIN_PRED_PROCESSED_PATH = \"./data_object_special/simmc2_dials_dstc10_train_predict.txt\"\n",
    "TRAIN_TARGET_PROCESSED_PATH = \"./data_object_special/simmc2_dials_dstc10_train_target.txt\"\n",
    "\n",
    "DEV_PRED_PROCESSED_PATH = \"./data_object_special/simmc2_dials_dstc10_dev_predict.txt\"\n",
    "DEV_TARGET_PROCESSED_PATH = \"./data_object_special/simmc2_dials_dstc10_dev_target.txt\"\n",
    "\n",
    "DEVTEST_PRED_PROCESSED_PATH = \"./data_object_special/simmc2_dials_dstc10_devtest_predict.txt\"\n",
    "DEVTEST_TARGET_PROCESSED_PATH = \"./data_object_special/simmc2_dials_dstc10_devtest_target.txt\"\n",
    "\n",
    "OUT_DOMAIN_REF_PATH = REF_SETS_BASE_PATH + \"/out_of_domain_test.json\"\n",
    "IN_DOMAIN_HELD_OUT_REF_PATH = REF_SETS_BASE_PATH + \"/in_domain_held_out_test.json\"\n",
    "IN_DOMAIN_REF_PATH = REF_SETS_BASE_PATH + \"/in_domain_test.json\"\n",
    "TRAIN_REF_PATH = REF_SETS_BASE_PATH + \"/seen_unseen_OOD_train.json\"\n",
    "\n",
    "OUT_DOMAIN_PRED_STORE_PATH = STORE_BASE_PATH + \"/out_of_domain_predict.txt\"\n",
    "OUT_DOMAIN_TARGET_STORE_PATH = STORE_BASE_PATH + \"/out_of_domain_target.txt\"\n",
    "\n",
    "IN_DOMAIN_HELD_OUT_PRED_STORE_PATH = STORE_BASE_PATH + \"/in_domain_held_out_predict.txt\"\n",
    "IN_DOMAIN_HELD_OUT_TARGET_STORE_PATH = STORE_BASE_PATH + \"/in_domain_held_out_target.txt\"\n",
    "\n",
    "IN_DOMAIN_PRED_STORE_PATH = STORE_BASE_PATH + \"/in_domain_predict.txt\"\n",
    "IN_DOMAIN_TARGET_STORE_PATH = STORE_BASE_PATH + \"/in_domain_target.txt\"\n",
    "\n",
    "TRAIN_PRED_STORE_PATH = STORE_BASE_PATH + \"/train_seen_unseen_OOD_predict.txt\"\n",
    "TRAIN_TARGET_STORE_PATH = STORE_BASE_PATH + \"/train_seen_unseen_OOD_target.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_fashion_examples(predict_path_list, target_path_list):\n",
    "    all_predict_ex = []\n",
    "    all_target_ex = []\n",
    "\n",
    "    assert len(predict_path_list) == len(target_path_list)\n",
    "\n",
    "    for i in range(len(predict_path_list)):\n",
    "        with open(target_path_list[i], 'r') as f:\n",
    "            target_data = f.readlines()\n",
    "        \n",
    "        with open(predict_path_list[i], 'r') as f:\n",
    "            for line_idx, line in enumerate(f.readlines()):\n",
    "                if len(line) > 1:\n",
    "                    idx = line.find(\"<@\")\n",
    "                    if line[idx+2] == '1': # fashion example\n",
    "                        all_predict_ex.append(line)\n",
    "                        all_target_ex.append(target_data[line_idx])\n",
    "\n",
    "    return all_predict_ex, all_target_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37610 37610\n"
     ]
    }
   ],
   "source": [
    "pred_path_list = [TRAIN_PRED_PROCESSED_PATH, DEV_PRED_PROCESSED_PATH, DEVTEST_PRED_PROCESSED_PATH]\n",
    "target_path_list = [TRAIN_TARGET_PROCESSED_PATH, DEV_TARGET_PROCESSED_PATH, DEVTEST_TARGET_PROCESSED_PATH]\n",
    "all_fash_pred_ex, all_fash_target_ex = get_all_fashion_examples(pred_path_list, target_path_list)\n",
    "\n",
    "print(len(all_fash_pred_ex), len(all_fash_target_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_last_sys_turn(line):\n",
    "    check = line.find(\"<@\")\n",
    "    idx_sys = line.rfind('System :')\n",
    "    if check == -1: # UNITER MODEL\n",
    "        idx_som = line.rfind(' System mentions :')\n",
    "        if idx_som == -1 or idx_som < idx_sys:\n",
    "            idx_som = line.rfind(' User :')\n",
    "\n",
    "    else: # BART MODEL\n",
    "        idx_som = line.rfind(' <SOM>')\n",
    "    \n",
    "    if idx_sys != -1 and idx_som != -1:\n",
    "        return line[idx_sys+len('System : '):idx_som]\n",
    "    if idx_sys != -1:\n",
    "        return line[idx_sys+len('System : '):]\n",
    "    return -1\n",
    "\n",
    "\n",
    "def _get_last_user_turn(line):\n",
    "    idx_usr = line.rfind('User :')\n",
    "    idx_soo = line.find(' <SOO>')\n",
    "    if idx_soo != -1:\n",
    "        return line[idx_usr+len('User : '):idx_soo]\n",
    "    return line[idx_usr+len('User : '):]\n",
    "\n",
    "\n",
    "def _get_line_object_ids(line):\n",
    "    line_ids = []\n",
    "    pos = 0\n",
    "    idx = line.find(\"<@\", pos)\n",
    "    while idx != -1:\n",
    "        # get absolute object ID\n",
    "        abs_id = line[idx+3:idx+6]\n",
    "        line_ids.append(int(abs_id)+1)\n",
    "        # update pos and idx\n",
    "        pos = idx+4\n",
    "        idx = line.find(\"<@\", pos)\n",
    "    return line_ids\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_examples_given_ref(ref_path, all_fash_pred_examples, all_fash_target_examples):\n",
    "    with open(ref_path, 'r') as f:\n",
    "        ref_data = json.load(f)\n",
    "    \n",
    "    pred_examples = []\n",
    "    target_examples = []\n",
    "\n",
    "    for line in tqdm(ref_data):\n",
    "        check = False\n",
    "        aux_list = []\n",
    "        last_user_turn = _get_last_user_turn(line['dial'])\n",
    "        last_sys_turn = _get_last_sys_turn(line['dial'])\n",
    "        KB_ids = line['KB_ids']\n",
    "        temp_pred = []\n",
    "        temp_target = []\n",
    "        for idx, example in enumerate(all_fash_pred_examples):\n",
    "            if last_user_turn == _get_last_user_turn(example) and last_sys_turn == _get_last_sys_turn(example):\n",
    "                aux_list.append((example, idx))\n",
    "                if set(sorted(_get_line_object_ids(example))) <= set(sorted(KB_ids)):\n",
    "                    check = True\n",
    "                    temp_pred.append(example)\n",
    "                    temp_target.append(all_fash_target_examples[idx])\n",
    "                    #pred_examples.append(example)\n",
    "                    #target_examples.append(all_fash_target_examples[idx])\n",
    "        if not check and len(aux_list) == 1:\n",
    "            pred_examples.append(aux_list[0][0])\n",
    "            target_examples.append(all_fash_target_examples[aux_list[0][1]])\n",
    "            continue\n",
    "        if len(temp_pred) > 1:\n",
    "            if 'bad image' in last_user_turn:\n",
    "                continue\n",
    "            print(\"Warning: skipping\", len(temp_pred), \"examples\")\n",
    "            continue\n",
    "            \"\"\"\n",
    "            print(\"COUNTER\")\n",
    "            print(last_user_turn)\n",
    "            print(last_sys_turn)\n",
    "            print(line['dial'])\n",
    "            print(line['dial_idx'])\n",
    "            print(line['KB_ids'])\n",
    "            break\n",
    "            \"\"\"\n",
    "        if not check:\n",
    "            print(last_user_turn)\n",
    "            print(last_sys_turn)\n",
    "            print(line['dial'])\n",
    "            print(line['KB_ids'])\n",
    "            print(\"CHECK ERROR\")\n",
    "            break\n",
    "        pred_examples += temp_pred\n",
    "        target_examples += temp_target\n",
    "    \n",
    "    return pred_examples, target_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 6999/9567 [04:38<01:41, 25.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skipping 2 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 8058/9567 [05:20<00:59, 25.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skipping 2 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8529/9567 [05:38<00:41, 25.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skipping 2 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9567/9567 [06:20<00:00, 25.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9558 9558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "in_dom_held_out_predict, in_dom_held_out_target = get_examples_given_ref(IN_DOMAIN_HELD_OUT_REF_PATH, all_fash_pred_ex, all_fash_target_ex)\n",
    "\n",
    "print(len(in_dom_held_out_predict), len(in_dom_held_out_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 144/9000 [00:05<05:51, 25.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skipping 2 examples\n",
      "Warning: skipping 2 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 498/9000 [00:19<05:36, 25.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skipping 2 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1602/9000 [01:03<04:53, 25.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skipping 2 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2079/9000 [01:22<04:36, 25.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skipping 2 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 3762/9000 [02:29<03:28, 25.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skipping 4 examples\n",
      "Warning: skipping 4 examples\n",
      "Warning: skipping 4 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6048/9000 [04:00<01:57, 25.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skipping 2 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 8937/9000 [05:55<00:02, 25.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skipping 4 examples\n",
      "Warning: skipping 4 examples\n",
      "Warning: skipping 4 examples\n",
      "Warning: skipping 4 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [05:57<00:00, 25.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8987 8987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "in_dom_predict, in_dom_target = get_examples_given_ref(IN_DOMAIN_REF_PATH, all_fash_pred_ex, all_fash_target_ex)\n",
    "\n",
    "print(len(in_dom_predict), len(in_dom_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 3375/14641 [02:13<07:24, 25.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skipping 2 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 10131/14641 [06:41<02:59, 25.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skipping 2 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14641/14641 [09:41<00:00, 25.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14633 14633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_predict, train_target = get_examples_given_ref(TRAIN_REF_PATH, all_fash_pred_ex, all_fash_target_ex)\n",
    "\n",
    "print(len(train_predict), len(train_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count number of candidate objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_object_special/simmc2_dials_dstc10_train_predict.txt', 'r') as f:\n",
    "    train_data = f.readlines()\n",
    "\n",
    "with open('./data_object_special/simmc2_dials_dstc10_dev_predict.txt', 'r') as f:\n",
    "    dev_data = f.readlines()\n",
    "\n",
    "with open('./data_object_special/simmc2_dials_dstc10_devtest_predict.txt', 'r') as f:\n",
    "    devtest_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_object_special/new_datasets/train_seen_unseen_OOD_predict.txt', 'r') as f:\n",
    "    train_cd_data = f.readlines()\n",
    "\n",
    "with open('./data_object_special/new_datasets/in_domain_predict.txt', 'r') as f:\n",
    "    indom_data = f.readlines()\n",
    "\n",
    "with open('./data_object_special/new_datasets/in_domain_held_out_predict.txt', 'r') as f:\n",
    "    idho_data = f.readlines()\n",
    "\n",
    "with open('./data_object_special/new_datasets/out_of_domain_predict.txt', 'r') as f:\n",
    "    ood_data = f.readlines()\n",
    "\n",
    "### Added:\n",
    "with open('./data_object_special/new_datasets/all_furniture_predict.txt', 'r') as f:\n",
    "    all_furn_data = f.readlines()\n",
    "\n",
    "with open('./data_object_special/new_datasets/devtest_only_fashion_predict.txt', 'r') as f:\n",
    "    devtest_only_fash_data = f.readlines()\n",
    "\n",
    "with open('./data_object_special/new_datasets/devtest_only_furniture_predict.txt', 'r') as f:\n",
    "    devtest_only_furn_data = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def count_mean_objs(data):\n",
    "    n_objs = []\n",
    "    for line in data:\n",
    "        n = 0\n",
    "        pos = line.find('<OBJ>')\n",
    "        while pos != -1:\n",
    "            n += 1\n",
    "            pos = line.find('<OBJ>', pos+1)\n",
    "        pos = line.find('<PREVIOBJ>')\n",
    "        while pos != -1:\n",
    "            n += 1\n",
    "            pos = line.find('<PREVIOBJ>', pos+1)\n",
    "        n_objs.append(n)\n",
    "    return np.mean(n_objs), np.std(n_objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.22089333018596\n",
      "31.029765311963367\n",
      "25.475316529213615\n",
      "32.880954008063966\n",
      "32.504006231916314\n",
      "24.012662201758058\n",
      "9.039772727272727\n",
      "30.66620858146282\n",
      "8.972815533980583\n",
      "9.028843106180666\n"
     ]
    }
   ],
   "source": [
    "print(count_mean_objs(train_data)[0])\n",
    "print(count_mean_objs(dev_data)[0])\n",
    "print(count_mean_objs(devtest_data)[0])\n",
    "\n",
    "print(count_mean_objs(train_cd_data)[0])\n",
    "print(count_mean_objs(indom_data)[0])\n",
    "print(count_mean_objs(idho_data)[0])\n",
    "print(count_mean_objs(ood_data)[0])\n",
    "\n",
    "\n",
    "print(count_mean_objs(devtest_only_fash_data)[0])\n",
    "print(count_mean_objs(devtest_only_furn_data)[0])\n",
    "print(count_mean_objs(all_furn_data)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.558003514569727\n",
      "31.029765311963367\n",
      "24.267510744569638\n",
      "31.07144446917427\n",
      "20.941816659690247\n"
     ]
    }
   ],
   "source": [
    "print(count_mean_objs(train_data)[0])\n",
    "print(count_mean_objs(dev_data)[0])\n",
    "print(count_mean_objs(devtest_data)[0])\n",
    "print(count_mean_objs(indom_data)[0])\n",
    "print(count_mean_objs(idho_data)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average number of objects per scene in the 'in domain' dataset is around 31, but the mean number of items per scene in the 'in domain held out' dataset is around 20.\n",
    "\n",
    "Examples: cloth_store_1498649_woman_3_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 120 # iamge resolution\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "train_cd_mean, train_cd_std = count_mean_objs(train_cd_data)\n",
    "indom_mean, indom_std = count_mean_objs(indom_data)\n",
    "idho_mean, idho_std = count_mean_objs(idho_data)\n",
    "ood_mean, ood_std = count_mean_objs(ood_data)\n",
    "\n",
    "means = [train_cd_mean, indom_mean, idho_mean, ood_mean]\n",
    "stds = [train_cd_std, indom_std, idho_std, ood_std]\n",
    "names = ['train-cd', 'in-domain', 'in-dom held-out', 'out domain']\n",
    "x_pos = np.arange(len(names))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x_pos, means, yerr=stds, alpha=0.9)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(names)\n",
    "ax.set_ylabel('Average no. objects per scene', weight='bold')\n",
    "ax.set_xlabel('Dataset', weight='bold')\n",
    "ax.set_title('Average no. objects per scene in cross-domain datasets', weight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b67ed9e9af8edfed5c6ad12438b07039e5eeda5b93411503796bc35acfdbeaa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
